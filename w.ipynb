{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b95d1b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeaz/Desktop/sentiment/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from transformers import AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7f6b96a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "emotion",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "91309e75-d546-4948-800a-d5529cc1efab",
       "rows": [
        [
         "0",
         "[RU] Эта игра причинила мне боль.",
         "['sadness']"
        ],
        [
         "1",
         "[RU] Ты правильно поступаешь, если тебе все равно, то иди к черту!",
         "['neutral']"
        ],
        [
         "2",
         "[RU] Чувак, я обожаю Reddit.",
         "['love']"
        ],
        [
         "3",
         "[RU] [ИМЯ] не было рядом с ними, он был рядом с «Соколом».",
         "['neutral']"
        ],
        [
         "4",
         "[RU] Верно? Учитывая, что это такой важный документ, я должен знать эту чертову штуку вдоль и поперек... еще раз спасибо за помощь!",
         "['gratitude']"
        ],
        [
         "5",
         "[RU] Он не такой большой, но все еще довольно популярный. Я слышал то же самое о его содержании. Никогда особо не смотрел его.",
         "['disapproval']"
        ],
        [
         "6",
         "[RU] Это безумие; Я училась в супер [РЕЛИГИЙНОЙ] средней школе и думаю, что за все 4 года могу вспомнить двух девочек, которые стали мамами-подростками.",
         "['amusement']"
        ],
        [
         "7",
         "[RU] это очень мило",
         "['amusement']"
        ],
        [
         "8",
         "[RU] «Пабы Sponge Blurb Quaw Haha GURR ha AAa!» финал слишком реален",
         "['amusement']"
        ],
        [
         "9",
         "[RU] Да, и теперь, когда вы упомянули об этом, я думаю, именно это вызвало у меня ностальгию.",
         "['neutral']"
        ],
        [
         "10",
         "[RU] Я хотел понизить это мнение, но это не твоя вина, приятель.",
         "['disappointment']"
        ],
        [
         "11",
         "[RU] НО ЭТО ОНА! /с",
         "['neutral']"
        ],
        [
         "12",
         "[RU] Это странно.",
         "['disappointment', 'disgust']"
        ],
        [
         "13",
         "[RU] Построить стену? /Джк",
         "['neutral']"
        ],
        [
         "14",
         "[RU] Я ценю это, приятно это знать. Надеюсь, однажды мне придется применить эти знания",
         "['admiration', 'gratitude']"
        ],
        [
         "15",
         "[RU] Однажды мой 1 остановился прямо на 91-м, я смог сделать хорошее фото платформы, так как вдоль нее есть несколько огней.",
         "['neutral']"
        ],
        [
         "16",
         "[RU] Ну тогда я бы сказал, что у тебя довольно хорошие шансы, если это какая-нибудь девушка, лол.",
         "['realization']"
        ],
        [
         "17",
         "[RU] Практически каждый пенджабский чувак, которого я встречал.",
         "['admiration']"
        ],
        [
         "18",
         "[RU] Для дополнительной меры закрепите его прямо у промежности, чтобы она не могла взять его по причинам сексуального насилия.",
         "['annoyance']"
        ],
        [
         "19",
         "[RU] На этом видео даже не показаны туфли, которые он носил...",
         "['neutral']"
        ],
        [
         "20",
         "[RU] За что Клемсону дарят наклейки гордости? Снапы играли?",
         "['confusion']"
        ],
        [
         "21",
         "[RU] «Ты можешь умереть, но я готов принести эту жертву»",
         "['optimism']"
        ],
        [
         "22",
         "[RU] Теперь мне интересно, что я упустил. Еще раз спасибо за это.",
         "['curiosity', 'gratitude']"
        ],
        [
         "23",
         "[RU] это определенно вписывается в r/BoneAppleTea.",
         "['neutral']"
        ],
        [
         "24",
         "[RU] «Виааа! У нас тоже есть один цветной!»",
         "['excitement']"
        ],
        [
         "25",
         "[RU] Напомни мне! 3 месяца",
         "['neutral']"
        ],
        [
         "26",
         "[RU] Да, больше нет. Поддерживайте уровень сахара в крови! Очень помогает, ПИТЬ ВОДУ...",
         "['caring']"
        ],
        [
         "27",
         "[RU] Много, Play Store или Apple Store VPN. Норд это хорошо",
         "['admiration']"
        ],
        [
         "28",
         "[RU] Я так рада за [ИМЯ]. Так грустно, что его здесь нет. Представьте себе эту команду с [ИМЯ] вместо [ИМЯ]. Фу.",
         "['disgust', 'joy', 'sadness']"
        ],
        [
         "29",
         "[RU] но это [ИМЯ] говорит так разочаровывает",
         "['neutral']"
        ],
        [
         "30",
         "[RU] Что-то Что-то Что-то, пространство вспомогательных средств",
         "['neutral']"
        ],
        [
         "31",
         "[RU] Мрачный и забавный, но не очень приятный парень. Ему еще предстоит назвать мертвых девушек шлюхами за то, что они отказались переспать с ним.",
         "['disappointment', 'disgust']"
        ],
        [
         "32",
         "[RU] Я, наверное, проехал пару сотен миль на своем компактном колесе. Это все еще там прямо сейчас.",
         "['neutral']"
        ],
        [
         "33",
         "[RU] Я рад, что с ним все в порядке, но я еще больше рад, что это не та самая гифка, где парень катается на лыжах или спускается с парашютом с горы.",
         "['gratitude']"
        ],
        [
         "34",
         "[RU] хороший!! я попробую это",
         "['admiration']"
        ],
        [
         "35",
         "[RU] Терпеть не могу [ИМЯ]. Особенно после ее видео «татуирую себе лицо».",
         "['disapproval']"
        ],
        [
         "36",
         "[RU] Я только что пришел домой, что это за состав? Я люблю тебя, [ИМЯ], ты безумный ублюдок!!!",
         "['love']"
        ],
        [
         "37",
         "[RU] Иди тролль в другом месте. Этой женщине нужна поддержка, а не грубые вопросы.",
         "['annoyance']"
        ],
        [
         "38",
         "[RU] Просто слухи в сети, скорее всего, этого не произойдет.",
         "['annoyance']"
        ],
        [
         "39",
         "[RU] На. Редактирую свой пост. Извините за невежество.",
         "['remorse']"
        ],
        [
         "40",
         "[RU] Поскольку создатели контента не заслуживают оплаты, ваши секунды, потраченные на прослушивание рекламы, слишком ценны!",
         "['confusion', 'curiosity']"
        ],
        [
         "41",
         "[RU] Жалость. У меня было несколько приличных обедов там, но я никогда не ходил туда ночью.",
         "['remorse']"
        ],
        [
         "42",
         "[RU] Пожалуй, самое крутое, что я видел в этой теме",
         "['joy']"
        ],
        [
         "43",
         "[RU] Какие доказательства вообще свидетельствуют о том, что [ИМЯ] был соучастником?",
         "['neutral']"
        ],
        [
         "44",
         "[RU] >не панацея. Раз у нас такого нет, разве это не следующий лучший вариант?",
         "['confusion']"
        ],
        [
         "45",
         "[RU] Если есть закономерность, то да.",
         "['approval']"
        ],
        [
         "46",
         "[RU] Если [ИМЯ] будет выполнять аналогичную роль до конца года, то я ни в коем случае не возьму его на себя... особенно Sony",
         "['neutral']"
        ],
        [
         "47",
         "[RU] Ой, ой, я неправильно прочитала исходный комментарий",
         "['confusion', 'realization']"
        ],
        [
         "48",
         "[RU] Посылаю вибрации любви и силы <3",
         "['joy', 'optimism']"
        ],
        [
         "49",
         "[RU] С ними она как кукла Кьюпи. Драгоценный.",
         "['admiration']"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 479725
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[RU] Эта игра причинила мне боль.</td>\n",
       "      <td>['sadness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[RU] Ты правильно поступаешь, если тебе все ра...</td>\n",
       "      <td>['neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[RU] Чувак, я обожаю Reddit.</td>\n",
       "      <td>['love']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[RU] [ИМЯ] не было рядом с ними, он был рядом ...</td>\n",
       "      <td>['neutral']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[RU] Верно? Учитывая, что это такой важный док...</td>\n",
       "      <td>['gratitude']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479720</th>\n",
       "      <td>[KZ] \"Сен онымен на хабаре болсаң, менің өтіні...</td>\n",
       "      <td>['desire', 'caring', 'nervousness']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479721</th>\n",
       "      <td>[KZ] \"Оның \"танкасы бар\" болса да, заң алдында...</td>\n",
       "      <td>['approval', 'determination', 'anger']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479722</th>\n",
       "      <td>[KZ] \"Ол шындықты айтып тұр ма, или өтірік пе,...</td>\n",
       "      <td>['curiosity', 'nervousness', 'confusion']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479723</th>\n",
       "      <td>[KZ] Университетте оқып жүргенде, біз общягада...</td>\n",
       "      <td>['nostalgia', 'caring', 'joy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479724</th>\n",
       "      <td>[KZ] \"Қораға кіргеніңді түсінген кезде кеш бол...</td>\n",
       "      <td>['caring', 'disapproval', 'realization']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>479725 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  \\\n",
       "0                       [RU] Эта игра причинила мне боль.   \n",
       "1       [RU] Ты правильно поступаешь, если тебе все ра...   \n",
       "2                            [RU] Чувак, я обожаю Reddit.   \n",
       "3       [RU] [ИМЯ] не было рядом с ними, он был рядом ...   \n",
       "4       [RU] Верно? Учитывая, что это такой важный док...   \n",
       "...                                                   ...   \n",
       "479720  [KZ] \"Сен онымен на хабаре болсаң, менің өтіні...   \n",
       "479721  [KZ] \"Оның \"танкасы бар\" болса да, заң алдында...   \n",
       "479722  [KZ] \"Ол шындықты айтып тұр ма, или өтірік пе,...   \n",
       "479723  [KZ] Университетте оқып жүргенде, біз общягада...   \n",
       "479724  [KZ] \"Қораға кіргеніңді түсінген кезде кеш бол...   \n",
       "\n",
       "                                          emotion  \n",
       "0                                     ['sadness']  \n",
       "1                                     ['neutral']  \n",
       "2                                        ['love']  \n",
       "3                                     ['neutral']  \n",
       "4                                   ['gratitude']  \n",
       "...                                           ...  \n",
       "479720        ['desire', 'caring', 'nervousness']  \n",
       "479721     ['approval', 'determination', 'anger']  \n",
       "479722  ['curiosity', 'nervousness', 'confusion']  \n",
       "479723             ['nostalgia', 'caring', 'joy']  \n",
       "479724   ['caring', 'disapproval', 'realization']  \n",
       "\n",
       "[479725 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('mainData.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a875b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_individual_emotion_token(token_str):\n",
    "    if not isinstance(token_str, str):\n",
    "        return \"\"\n",
    "    \n",
    "    s = token_str.strip()\n",
    "    \n",
    "    s = s.replace(\"['\", \"\")\n",
    "    s = s.replace(\"']\", \"\")\n",
    "    s = s.replace(\"[\\\"\", \"\")\n",
    "    s = s.replace(\"\\\"]\", \"\")\n",
    "    s = s.replace(\"[\", \"\")\n",
    "    s = s.replace(\"]\", \"\")\n",
    "    s = s.replace(\"'\", \"\")\n",
    "    s = s.replace('\"', \"\")\n",
    "    \n",
    "    return s.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82d39bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_emotion_processor_updated(entry):\n",
    "    if pd.isna(entry):\n",
    "        return []\n",
    "    \n",
    "    processed_emotions = []\n",
    "    if isinstance(entry, list):\n",
    "        for item in entry:\n",
    "            cleaned_token = clean_individual_emotion_token(item)\n",
    "            processed_emotions.append(cleaned_token)\n",
    "    elif isinstance(entry, str):\n",
    "        if not entry.strip():\n",
    "            return []\n",
    "        \n",
    "        split_emotions = entry.split(',')\n",
    "        for item_from_split in split_emotions:\n",
    "            cleaned_token = clean_individual_emotion_token(item_from_split)\n",
    "            if cleaned_token:\n",
    "                processed_emotions.append(cleaned_token)\n",
    "    \n",
    "    final_emotions = []\n",
    "    if processed_emotions:\n",
    "        seen = set()\n",
    "        for em in processed_emotions:\n",
    "            if em not in seen:\n",
    "                final_emotions.append(em)\n",
    "                seen.add(em)\n",
    "    return final_emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e22a6b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels (num_labels): 55\n",
      "Classes: ['admiration' 'amusement' 'anger' 'annoyance' 'anticipation' 'anxiety'\n",
      " 'approv' 'approval' 'caring' 'caution' 'concern' 'confidence' 'confusion'\n",
      " 'contentment' 'creativity' 'curiosity' 'deceit' 'desire' 'determination'\n",
      " 'disappointment' 'disapproval' 'disbelief' 'discomfort' 'disgust'\n",
      " 'embarrassment' 'envy' 'excitement' 'fear' 'frustration' 'gratitude'\n",
      " 'grief' 'hope' 'joy' 'love' 'nervousness' 'neutral' 'nostalgia'\n",
      " 'optimism' 'panic' 'passion' 'pride' 'realization' 'reassurance' 'regret'\n",
      " 'relief' 'remorse' 'sadness' 'satisfaction' 'shame' 'shock' 'surprise'\n",
      " 'suspicion' 'tradition' 'trust' 'urgency']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['emotion_list_processed'] = data['emotion'].apply(robust_emotion_processor_updated)\n",
    "\n",
    "mlb_for_model_config = MultiLabelBinarizer()\n",
    "mlb_for_model_config.fit(data['emotion_list_processed'])\n",
    "num_labels = len(mlb_for_model_config.classes_)\n",
    "print(f\"Number of unique labels (num_labels): {num_labels}\")\n",
    "print(f\"Classes: {mlb_for_model_config.classes_}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "special_tokens_dict = {'additional_special_tokens': ['[KZ]', '[RU]', '[EN]']}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f05ba69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = str(text)\n",
    "\n",
    "    match = re.match(r\"\\[(KZ|RU|EN)\\]\", text)\n",
    "    lang_tag = match.group(0) if match else \"\"\n",
    "\n",
    "    text_wo_tag = text.replace(lang_tag, \"\") if lang_tag else text\n",
    "\n",
    "    text_wo_tag = text_wo_tag.lower()\n",
    "    text_wo_tag = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text_wo_tag)\n",
    "    text_wo_tag = re.sub(r\"\\s+\", \" \", text_wo_tag).strip()\n",
    "\n",
    "    return f\"{lang_tag} {text_wo_tag}\" if lang_tag else text_wo_tag\n",
    "\n",
    "def get_language_weight(text):\n",
    "    if text.startswith('[KZ]'):\n",
    "        return 2.0\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "def preprocess_multilingual_multilabel_cleaned(data):\n",
    "    data['cleaned_text_internal'] = data['text'].apply(clean_text)\n",
    "    data['weights_internal'] = data['cleaned_text_internal'].apply(get_language_weight)\n",
    "    weights_tensor = torch.tensor(data['weights_internal'].values, dtype=torch.float)\n",
    "\n",
    "    if 'emotion_list_processed' not in data.columns:\n",
    "        print(\"Warning: 'emotion_list_processed' column not found in input to preprocess_multilingual_multilabel_cleaned. Creating it now.\")\n",
    "        if not hasattr(data, 'emotion_list_processed'): # Check if the global step actually added it.\n",
    "             data['emotion_list_processed'] = data['emotion'].apply(robust_emotion_processor_lambda)\n",
    "\n",
    "\n",
    "    internal_mlb = MultiLabelBinarizer()\n",
    "    y_transformed = internal_mlb.fit_transform(data['emotion_list_processed'])\n",
    "\n",
    "    encodings = tokenizer(\n",
    "        data['cleaned_text_internal'].tolist(),\n",
    "        truncation=True,\n",
    "        padding=True,\n",
    "        max_length=128,\n",
    "        return_tensors=\"pt\",\n",
    "        return_token_type_ids=False\n",
    "    )\n",
    "\n",
    "    return encodings, torch.tensor(y_transformed, dtype=torch.float), internal_mlb, weights_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "787ecc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "la = data['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c88d5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "db84c727-b10a-4fff-a781-8b018a1197fb",
       "rows": [
        [
         "0",
         "[RU] эта игра причинила мне боль."
        ],
        [
         "1",
         "[RU] ты правильно поступаешь, если тебе все равно, то иди к черту!"
        ],
        [
         "2",
         "[RU] чувак, я обожаю reddit."
        ],
        [
         "3",
         "[RU] [имя] не было рядом с ними, он был рядом с «соколом»."
        ],
        [
         "4",
         "[RU] верно? учитывая, что это такой важный документ, я должен знать эту чертову штуку вдоль и поперек... еще раз спасибо за помощь!"
        ],
        [
         "5",
         "[RU] он не такой большой, но все еще довольно популярный. я слышал то же самое о его содержании. никогда особо не смотрел его."
        ],
        [
         "6",
         "[RU] это безумие; я училась в супер [религийной] средней школе и думаю, что за все 4 года могу вспомнить двух девочек, которые стали мамами-подростками."
        ],
        [
         "7",
         "[RU] это очень мило"
        ],
        [
         "8",
         "[RU] «пабы sponge blurb quaw haha gurr ha aaa!» финал слишком реален"
        ],
        [
         "9",
         "[RU] да, и теперь, когда вы упомянули об этом, я думаю, именно это вызвало у меня ностальгию."
        ],
        [
         "10",
         "[RU] я хотел понизить это мнение, но это не твоя вина, приятель."
        ],
        [
         "11",
         "[RU] но это она! /с"
        ],
        [
         "12",
         "[RU] это странно."
        ],
        [
         "13",
         "[RU] построить стену? /джк"
        ],
        [
         "14",
         "[RU] я ценю это, приятно это знать. надеюсь, однажды мне придется применить эти знания"
        ],
        [
         "15",
         "[RU] однажды мой 1 остановился прямо на 91-м, я смог сделать хорошее фото платформы, так как вдоль нее есть несколько огней."
        ],
        [
         "16",
         "[RU] ну тогда я бы сказал, что у тебя довольно хорошие шансы, если это какая-нибудь девушка, лол."
        ],
        [
         "17",
         "[RU] практически каждый пенджабский чувак, которого я встречал."
        ],
        [
         "18",
         "[RU] для дополнительной меры закрепите его прямо у промежности, чтобы она не могла взять его по причинам сексуального насилия."
        ],
        [
         "19",
         "[RU] на этом видео даже не показаны туфли, которые он носил..."
        ],
        [
         "20",
         "[RU] за что клемсону дарят наклейки гордости? снапы играли?"
        ],
        [
         "21",
         "[RU] «ты можешь умереть, но я готов принести эту жертву»"
        ],
        [
         "22",
         "[RU] теперь мне интересно, что я упустил. еще раз спасибо за это."
        ],
        [
         "23",
         "[RU] это определенно вписывается в r/boneappletea."
        ],
        [
         "24",
         "[RU] «виааа! у нас тоже есть один цветной!»"
        ],
        [
         "25",
         "[RU] напомни мне! 3 месяца"
        ],
        [
         "26",
         "[RU] да, больше нет. поддерживайте уровень сахара в крови! очень помогает, пить воду..."
        ],
        [
         "27",
         "[RU] много, play store или apple store vpn. норд это хорошо"
        ],
        [
         "28",
         "[RU] я так рада за [имя]. так грустно, что его здесь нет. представьте себе эту команду с [имя] вместо [имя]. фу."
        ],
        [
         "29",
         "[RU] но это [имя] говорит так разочаровывает"
        ],
        [
         "30",
         "[RU] что-то что-то что-то, пространство вспомогательных средств"
        ],
        [
         "31",
         "[RU] мрачный и забавный, но не очень приятный парень. ему еще предстоит назвать мертвых девушек шлюхами за то, что они отказались переспать с ним."
        ],
        [
         "32",
         "[RU] я, наверное, проехал пару сотен миль на своем компактном колесе. это все еще там прямо сейчас."
        ],
        [
         "33",
         "[RU] я рад, что с ним все в порядке, но я еще больше рад, что это не та самая гифка, где парень катается на лыжах или спускается с парашютом с горы."
        ],
        [
         "34",
         "[RU] хороший!! я попробую это"
        ],
        [
         "35",
         "[RU] терпеть не могу [имя]. особенно после ее видео «татуирую себе лицо»."
        ],
        [
         "36",
         "[RU] я только что пришел домой, что это за состав? я люблю тебя, [имя], ты безумный ублюдок!!!"
        ],
        [
         "37",
         "[RU] иди тролль в другом месте. этой женщине нужна поддержка, а не грубые вопросы."
        ],
        [
         "38",
         "[RU] просто слухи в сети, скорее всего, этого не произойдет."
        ],
        [
         "39",
         "[RU] на. редактирую свой пост. извините за невежество."
        ],
        [
         "40",
         "[RU] поскольку создатели контента не заслуживают оплаты, ваши секунды, потраченные на прослушивание рекламы, слишком ценны!"
        ],
        [
         "41",
         "[RU] жалость. у меня было несколько приличных обедов там, но я никогда не ходил туда ночью."
        ],
        [
         "42",
         "[RU] пожалуй, самое крутое, что я видел в этой теме"
        ],
        [
         "43",
         "[RU] какие доказательства вообще свидетельствуют о том, что [имя] был соучастником?"
        ],
        [
         "44",
         "[RU] >не панацея. раз у нас такого нет, разве это не следующий лучший вариант?"
        ],
        [
         "45",
         "[RU] если есть закономерность, то да."
        ],
        [
         "46",
         "[RU] если [имя] будет выполнять аналогичную роль до конца года, то я ни в коем случае не возьму его на себя... особенно sony"
        ],
        [
         "47",
         "[RU] ой, ой, я неправильно прочитала исходный комментарий"
        ],
        [
         "48",
         "[RU] посылаю вибрации любви и силы <3"
        ],
        [
         "49",
         "[RU] с ними она как кукла кьюпи. драгоценный."
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 479725
       }
      },
      "text/plain": [
       "0                         [RU] эта игра причинила мне боль.\n",
       "1         [RU] ты правильно поступаешь, если тебе все ра...\n",
       "2                              [RU] чувак, я обожаю reddit.\n",
       "3         [RU] [имя] не было рядом с ними, он был рядом ...\n",
       "4         [RU] верно? учитывая, что это такой важный док...\n",
       "                                ...                        \n",
       "479720    [KZ] \"сен онымен на хабаре болсаң, менің өтіні...\n",
       "479721    [KZ] \"оның \"танкасы бар\" болса да, заң алдында...\n",
       "479722    [KZ] \"ол шындықты айтып тұр ма, или өтірік пе,...\n",
       "479723    [KZ] университетте оқып жүргенде, біз общягада...\n",
       "479724    [KZ] \"қораға кіргеніңді түсінген кезде кеш бол...\n",
       "Name: text, Length: 479725, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34c5b9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import TensorDataset\n",
    "from transformers import AutoModelForSequenceClassification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a90aa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilingualEmotionDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, weights):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.weights = weights\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        item['weight'] = self.weights[idx]\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81a1571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('bert-base-multilingual-cased',\n",
    "                                                           num_labels=num_labels,\n",
    "                                                           problem_type=\"multi_label_classification\")\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "encodings, labels, mlb_returned, weights = preprocess_multilingual_multilabel_cleaned(data.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9d3b8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['admiration' 'amusement' 'anger' 'annoyance' 'anticipation' 'anxiety'\n",
      " 'approv' 'approval' 'caring' 'caution' 'concern' 'confidence' 'confusion'\n",
      " 'contentment' 'creativity' 'curiosity' 'deceit' 'desire' 'determination'\n",
      " 'disappointment' 'disapproval' 'disbelief' 'discomfort' 'disgust'\n",
      " 'embarrassment' 'envy' 'excitement' 'fear' 'frustration' 'gratitude'\n",
      " 'grief' 'hope' 'joy' 'love' 'nervousness' 'neutral' 'nostalgia'\n",
      " 'optimism' 'panic' 'passion' 'pride' 'realization' 'reassurance' 'regret'\n",
      " 'relief' 'remorse' 'sadness' 'satisfaction' 'shame' 'shock' 'surprise'\n",
      " 'suspicion' 'tradition' 'trust' 'urgency']\n"
     ]
    }
   ],
   "source": [
    "print(mlb_returned.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "88c052cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(len(labels)))\n",
    "train_idx, val_idx = train_test_split(indices, test_size=0.1, random_state=42)\n",
    "\n",
    "train_encodings = {key: val[train_idx] for key, val in encodings.items()}\n",
    "val_encodings = {key: val[val_idx] for key, val in encodings.items()}\n",
    "\n",
    "train_labels = labels[train_idx]\n",
    "val_labels = labels[val_idx]\n",
    "\n",
    "train_weights = weights[train_idx]\n",
    "val_weights = weights[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9612b932",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MultilingualEmotionDataset(train_encodings, train_labels, train_weights)\n",
    "val_dataset = MultilingualEmotionDataset(val_encodings, val_labels, val_weights)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd255f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = BCEWithLogitsLoss(reduction='none')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8e8f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, batch in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).float()\n",
    "        weights = batch['weight'].to(device).float()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        raw_loss = criterion(logits, labels)\n",
    "        weighted_loss = (raw_loss.mean(dim=1) * weights).mean()\n",
    "\n",
    "        weighted_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += weighted_loss.item()\n",
    "\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Batch {i+1} - Loss: {weighted_loss.item():.4f}\")\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1} - Train loss: {avg_train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d56bbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in val_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device).float()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.sigmoid(logits).cpu().numpy()\n",
    "        target = labels.cpu().numpy()\n",
    "\n",
    "        all_preds.extend(preds)\n",
    "        all_targets.extend(target)\n",
    "\n",
    "pred_labels = (np.array(all_preds) >= 0.5).astype(int)\n",
    "f1 = f1_score(all_targets, pred_labels, average='micro')\n",
    "print(f\"Validation Micro F1: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8482bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "model.save_pretrained('mbert')\n",
    "tokenizer.save_pretrained('mbert')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218e095",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_directory = 'mbert'\n",
    "mlb_filename = 'mlb.joblib'\n",
    "mlb_path = os.path.join(model_directory, mlb_filename)\n",
    "\n",
    "joblib.dump(mlb_returned, mlb_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
